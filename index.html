<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <title>ROCLING 2021</title>

    
    <!-- 匯入bootstrap -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
  
  
    <!-- 匯入bootstrap -->
    <!-- <link rel="stylesheet" href="http://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/css/bootstrap.min.css"> -->

    <!-- 匯入jQuery -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>

    <!-- 匯入bootstrap javascript -->
    <!-- <script src="http://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script> -->

    <!-- Latest compiled and minified CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
    <!-- Optional theme -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap-theme.min.css" integrity="sha384-rHyoN1iRsVXV4nD0JutlnGaslCJuC7uwjduW9SVrLvRYooPp2bWYgmgJQIXwl/Sp" crossorigin="anonymous">
    <!-- Latest compiled and minified JavaScript -->
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

    


    

    <!-- <link rel="stylesheet" href="reset.css"> -->
    <link rel="stylesheet" href="main.css">
    <meta name="viewport" content="width=device-width, initial-scale=1">
</head>

<body>

<!-- ============================================================================ -->


    <div>
        <nav class="nav navbar-default navbar-fixed-top topflex" id="topdiv">

            <div class="navbar-header" id="navheader">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#collapsingNavbarMd">
                    <span class="sr-only"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
            </div>

            <div class="collapse navbar-collapse navbar-collapse-center" id="collapsingNavbarMd">
                <ul class="nav navbar-nav navbar-center" >
                    <li class="single"><a href="javascript:;" class="navItems" navTo="#">Home</a></li>

                    <li class="single"><a href="javascript:;" class="navItems" navTo="#call_paper">Call for Papers</a></li>

                    <li class="single"><a href="javascript:;" class="navItems" navTo="#programs">Programs</a></li>

                    <li class="single"><a href="javascript:;" class="navItems" navTo="#registration">Registration</a></li>

                    <li class="single"><a href="javascript:;" class="navItems" navTo="#key_note">Keynote Speakers</a></li>

                    <li class="single"><a href="javascript:;" class="navItems" navTo="#tutor">Tutorials</a></li>
                    
                    <li class="single"><a href="javascript:;" class="navItems" navTo="#special">Special Session</a></li>

                    <li class="single"><a href="javascript:;" class="navItems" navTo="#task">Shared Task</a></li>

                    <li class="single"><a href="javascript:;" class="navItems" navto='#org'>Organization</a></li>

                    <li class="single"><a href="mailto:rocling2021@gmail.com" class="navItems" navto=''>Contact</a></li>

                    <!-- <li class="dropdown">
                        <a class="dropdown-toggle" data-toggle="dropdown">Information</a>
                        <ul class="dropdown-menu">
                            <li><a href="javascript:;" class="navItems" navto='#'>Accomoodation</a></li>
                            <li><a href="javascript:;" class="navItems" navto='#'>Transportation</a></li>
                            <li><a href="javascript:;" class="navItems" navto='#'>Venue</a></li>
                        </ul>
                    </li> -->
                </ul>
            </div>
        </nav>
    </div>
   

    <!-- ============================================================================ -->

    <div class="banner" id="ban">
        <img src="image/main_banner.jpeg" alt="banner">
    </div>

    <!-- ============================================================================ -->

    <div class="announcement">
        <div class="bg">

        <div class="news">
            <div id="carouselExampleCaptions" class="carousel slide" data-ride="carousel">
                
                <ol class="carousel-indicators">
                    <li data-target="#carouselExampleCaptions" data-slide-to="0" class="active"></li>
                    <li data-target="#carouselExampleCaptions" data-slide-to="1"></li>
                    <li data-target="#carouselExampleCaptions" data-slide-to="2"></li>
                    <li data-target="#carouselExampleCaptions" data-slide-to="3"></li>
                </ol>

                <div class="carousel-inner">

                    <div class="carousel-item active">
                        <img src="image/side/pink.jpeg" class="" alt="...">
                        <div class="carousel-caption align-items-center">
                            <h1>ROCLING 2021 is going hybrid</h1>
                            <p>Due to the uncertainty of COVID-19 pandemic, our conference will be delivered in a hybrid event format, combining an on-site paper presentation (except foreign speakers) with online participation and live QA.</p>
                        </div>
                    </div>

                    <div class="carousel-item">
                        <img src="image/side/ncu_gate.jpg" class="" alt="...">
                    </div>

                    <div class="carousel-item">
                        <img src="image/side/pink.jpeg" class="" alt="...">
                        <div class="carousel-caption align-items-center">
                            <h1>Download Slide Template</h1>
                            <p>We strongly suggest the authors using the <a href="ROCLING2021_SlideTemplate.pptx" target="_blank" title="uninstructed">ROCLING 2021 slide template</a> to prepare their oral presentation.
                                Please send us your presentation slide via the email  <a href="mailto:rocling2021@gmail.com" target="_blank" title="uninstructed">rocling2021@gmail.com</a> by October 12.
                            </p>
                        </div>
                    </div>

                    <div class="carousel-item">
                        <img src="image/side/gate.jpg" class="" alt="...">
                    </div>

                    <a class="carousel-control-prev" href="#carouselExampleCaptions" role="button" data-slide="prev">
                        <span class="carousel-control-prev-icon" aria-hidden="true"></span>
                        <span class="sr-only">Previous</span>
                    </a>
                    <a class="carousel-control-next" href="#carouselExampleCaptions" role="button" data-slide="next">
                        <span class="carousel-control-next-icon" aria-hidden="true"></span>
                        <span class="sr-only">Next</span>
                    </a>
                </div>
                
            </div>
        </div>

        <div class="importantdate" id="imd">
            
                <div class="flex" id="imd_flex">
                    <h1>Important Dates</h1>

                    <div class="item">
                        <ul>
                            <li>Paper Submission Due: <s>July 23, 2021</s> <br>
                                <p class="opa">Paper Submission Due: </p><p class="date_update">August 6, 2021</p></li>
                            <li>Notification of acceptance: <s>August 27, 2021</s> <br>
                                <p class="opa">Notification of acceptance: </p> <p class="date_update">September 3, 2021</p></li>
                            <li>Camera-ready due: September 10, 2021</li>
                            <li>Early Registration ends: September 15, 2021</li>
                            <li>Late Registration ends: October 5, 2021</li>
                            <li>On-Site Registration: October 15-16, 2021</li>
                        </ul>
                    </div>
                    
                    <p>All deadlines are 11.59 pm UTC-12h (anywhere on earth)</p>
                </div>
            
        </div>

        </div>
    </div>

    <!-- ============================================================================ -->

    <div class="welcome">
        <div class="wrap">
            <div class="item pic">
                <img src="image/rocling2021_history.jpg" alt="">  
            </div>
            <div class="item text">
                <h1>Welcome to ROCLING 2021!</h1>
                <div class="content">
                    
                    <p>ROCLING 2021 is the 33rd annual Conference on Computational Linguistics and Speech Processing in Taiwan sponsored by the Association for Computational Linguistics and Chinese Language Processing (ACLCLP).The conference will be held in the Engineering Building 5 of National Central University (NCU) in Taoyuan, Taiwan during October 15-16, 2021.
                    </p>

                    <p>ROCLING 2021 will provide an international forum for researchers and industry practitioners to share their new ideas, original research results and practical development experiences from all language and speech research areas, including computational linguistics, information understanding, and signal processing. ROCLING 2021 will feature oral papers, posters, tutorials, special sessions and shared tasks.  
                    </p>

                    <p>The conference on Computational Linguistics and Speech Processing (ROCLING) was initiated in 1988 by the Association for Computational Linguistics and Chinese Language Processing (ACLCLP) with the major goal to provide a platform for researchers and professionals from around the world to share their experiences related to natural language processing and speech processing. Following are a list of past ROCLING conferences.
                    </p>
                </div>
            </div>
        </div>
    </div>

    <!-- ============================================================================ -->

    <div class="paper" id="call_paper">

        <h1>Call for Papers</h1>
        
        <div class="introduce_div_before">
            <div class="introduce_div">
                <p>ROCLING 2021 invites paper submissions reporting original research results and system development experiences as well as real-world applications. Each submission will be reviewed based on originality, significance, technical soundness, and relevance to the conference. Accepted papers will be presented orally or as poster presentations. Both oral and poster presentations will be published in the ROCLING 2021 conference proceedings and included in the ACL Anthology. A number of papers will be selected and invited for extension into journal versions and publication in a special issue of the International Journal of Computational Linguistics and Chinese Language Processing (IJCLCLP).
                </p>
                <p>Papers can be written and presented in either Chinese or English. Papers should be made in PDF format and submitted online through the paper submission system. Submitted papers may consist of 4-8 pages of content, plus unlimited references. Upon acceptance, final versions will be given additional pages of content (up to 9 pages) so that reviewers’ comments can be taken into account. ROCLING 2021 mainly targets two scientific tracks: natural language processing (NLP) and speech processing (Speech). Relevant topics for the conference include, but are not limited to, the following areas (in alphabetical order):
                </p>
            </div>
        </div>
        
        <div class="table_div_mid">

            <table id='paper-table-1'>
                <tr>
                    <th>Natural Language Processing</th>
                    <th>Speech Processing</th>
                </tr>

                <tr>
                    <td>
                        <ul style="text-align:left">
                            <li>Cognitive/Psychological Linguistics</li>
                            <li>Discourse and Pragmatics</li>
                            <li>Dialogue System</li>
                            <li>Information Extraction</li>
                            <li>Information Retrieval</li>
                            <li>Language Generation</li>
                            <li>Machine Translation</li>
                            <li>NLP Applications</li>
                            <li>Phonology, Morphology and Word Segmentation</li>
                            <li>Question Answering</li>
                            <li>Resources and Evaluation</li>
                            <li>Semantics: Lexical, Sentence-Level, Textual Inference</li>
                            <li>Sentiment Analysis</li>
                            <li>Summarization</li>
                            <li>Syntax: Tagging, Chunking and Parsing</li>
                            <li>Others</li>
                        </ul>
                    </td>

                    <td>
                        <ul style="text-align:left">
                            <li>Speech Perception, Production and Acquisition</li>
                            <li>Phonetics, Phonology and Prosody</li>
                            <li>Analysis of Paralinguistics in Speech and Language</li>
                            <li>Speaker and Language Identification</li>
                            <li>Analysis of Speech and Audio Signals</li>
                            <li>Speech Coding and Enhancement</li>
                            <li>Speech Synthesis and Spoken Language Generation</li>
                            <li>Speech Recognition</li>
                            <li>Spoken Dialog Systems and Analysis of Conversation</li>
                            <li>Spoken Language Processing:<br> Retrieval, Translation, Summarization, Resources and Evaluation</li>
                            <li>Others</li>
                        </ul>
                    </td>

                </tr>
            </table>

            <table id='paper-table-2'>
                <tr>
                    <th>Natural Language Processing</th>   
                </tr>
                <tr>
                    <td>
                        <ul style="text-align:left">
                            <li>Cognitive/Psychological Linguistics</li>
                            <li>Discourse and Pragmatics</li>
                            <li>Dialogue System</li>
                            <li>Information Extraction</li>
                            <li>Information Retrieval</li>
                            <li>Language Generation</li>
                            <li>Machine Translation</li>
                            <li>NLP Applications</li>
                            <li>Phonology, Morphology and Word Segmentation</li>
                            <li>Question Answering</li>
                            <li>Resources and Evaluation</li>
                            <li>Semantics: Lexical, Sentence-Level, Textual Inference</li>
                            <li>Sentiment Analysis</li>
                            <li>Summarization</li>
                            <li>Syntax: Tagging, Chunking and Parsing</li>
                            <li>Others</li>
                        </ul>
                    </td>
                </tr>

                <tr>
                    <th>Speech Processing</th>
                </tr>

                <tr>
                    <td>
                        <ul style="text-align:left">
                            <li>Speech Perception, Production and Acquisition</li>
                            <li>Phonetics, Phonology and Prosody</li>
                            <li>Analysis of Paralinguistics in Speech and Language</li>
                            <li>Speaker and Language Identification</li>
                            <li>Analysis of Speech and Audio Signals</li>
                            <li>Speech Coding and Enhancement</li>
                            <li>Speech Synthesis and Spoken Language Generation</li>
                            <li>Speech Recognition</li>
                            <li>Spoken Dialog Systems and Analysis of Conversation</li>
                            <li>Spoken Language Processing:<br> Retrieval, Translation, Summarization, Resources and Evaluation</li>
                            <li>Others</li>
                        </ul>
                    </td>

                </tr>
            </table>

           
        </div>

        <div class="introduce_div_after">
            <div class="introduce_div">
                <p>Paper submissions must use the official <a href="rocling2021-templates.zip" target="_blank" title="uninstructed">ROCLING 2021 style templates (Latex and Word)</a>.  
                    Submission is electronic, using the EasyChair conference management system. The submission 
                    site is available at <a href="https://easychair.org/conferences/?conf=rocling2021" target="_blank" title="uninstructed">https://easychair.org/conferences/?conf=rocling2021</a>.
                </p>

                <p>As the reviewing will be double-blind, papers must not include authors' names and affiliations. Furthermore, self-references that reveal the author's identity must be avoided. Papers that do not conform to these requirements will be rejected without review. Papers may be accompanied by a resource (software and/or data) described in the paper, but these resources should be anonymized as well.
                </p>

                <h2>Page Limitation - Camera-Ready Paper (applicable after acceptance)</h2>
                <p>According to the format of the paper template, the page limitations for accepted papers are 9 pages (plus unlimited references) in PDF format. The first page of the camera-ready version of the accepted paper should bear the items of paper title, author name, affiliation, and email address. All these items should be properly centered on the top, followed by a concise abstract of the paper.</p>

                <h2>Copyright Form (applicable after acceptance) <a href="rocling2021_copyright.doc" target="_blank" title="uninstructed">download here</a></h2>
                <p>Every accepted paper should also be sent with a signed copyright form in PDF format via the online registration system.</p>

            </div>
        </div>

    </div>
    <!-- ============================================================================ -->

    <div class='programs' id='programs'>
        <h1>Programs</h1>

        <div class='part'>
            <p style="text-align: center; font-size: 30px;"><a href="ROCLING2021_SlideTemplate.pptx" target="_blank" title="uninstructed">Download Slide Template</a></p>
        </div>
        
        <div class='part'>
            <h2>Friday, October 15, 2021</h2>
            <table>
                <tr>
                    <th width='15%'>TIME</th>
                    <th width='85%' colspan="2">EVENT</th>
                </tr>

                <tr>
                    <td>09:00 - 09:10</td>
                    <td colspan="2"><b>Opening Ceremony</b><br>(NCU E6-B520)</td>
                </tr>

                <tr>
                    <td>09:10 - 10:10</td>
                    <td colspan="2"><b>NLP Keynote by Prof. Vincent Ng</b><br>(NCU E6-B520)
                    </td>
                </tr>

                <tr>
                    <td>10:10 – 10:30</td>
                    <td colspan="2">Coffee Break</td>
                </tr>

                <tr>
                    <td>10:30 – 12:30</td>
                    <td width='40%'>Session 1<br> Speech and Language Processing-1<br>(NCU E6-B518)</td>
                    <td width='40%'>AI Tutorial I<br>(NCU E6-B520)</td>
                </tr>

                <tr>
                    <td>12:30 – 13:00</td>
                    <td colspan="2">Lunch</td>
                </tr>

                <tr>
                    <td>13:00 – 13:30</td>
                    <td colspan="2"><b>ACLCLP Assembly</b><br>(NCU E6-B520)</td>
                </tr>

                <tr>
                    <td>13:30 – 15:00</td>
                    <td width='40%'>Session 2<br>Information Retrieval and Text Mining<br>(NCU E6-B518)</td>
                    <td width='40%'> AI Tutorial II-1<br>(NCU E6-B520)</td>
                </tr>

                <tr>
                    <td>15:00 – 15:30</td>
                    <td colspan="2">Coffee Break</td>
                </tr>

                <tr>
                    <td>15:30 – 17:30</td>
                    <td width='40%'>Session 3<br>Best Paper Candidates<br>(NCU E6-B518)</td>
                    <td width='40%'>AI Tutorial II-2<br>(15:30 -17:00)<br>(NCU E6-B520)</td>
                </tr>

            </table>

        </div>

        <div class='part'>
            <h2>Saturday, October 16, 2021</h2>
            <table>
                <tr>
                    <th width='20%'>TIME</th>
                    <th width='80%' colspan="2">EVENT</th>
                </tr>

                <tr>
                    <td>09:00 - 10:00</td>
                    <td colspan="2"><b>Speech Keynote by Dr. Jinyu Li</b><br>(NCU E6-B520)
                    </td>
                </tr>

                <tr>
                    <td>10:00 – 10:20</td>
                    <td colspan="2">Coffee Break</td>
                </tr>

                <tr>
                    <td>10:20 – 12:20</td>
                    <td width='40%'>Session 4<br>Sentiment Analysis and Social Media<br>(NCU E6-B518)</td>
                    <td width='40%'>Special Session<br>Brain and Language<br>(NCU E6-B520)</td>
                </tr>

                <tr>
                    <td>12:20 – 12:50</td>
                    <td colspan="2">Lunch</td>
                </tr>

                <tr>
                    <td>12:50 – 13:30</td>
                    <td>Shared Task<br>
                        Dimensional Sentiment Analysis for Educational Texts<br>
                        (NCU E6-B518)
                    </td>
                    <td>AI Tutorial III<br>(NCU E6-B520)</td>
                </tr>

                <tr>
                    <td>13:30 – 15:00</td>
                    <td width='40%'>Session 5<br>Applications<br>(NCU E6-B518)</td>
                    <td width='40%'>AI Tutorial IV-1<br>(NCU E6-B520)</td>
                </tr>

                <tr>
                    <td>15:00 – 15:30</td>
                    <td colspan="2">Coffee Break</td>
                </tr>

                <tr>
                    <td>15:30 – 17:00</td>
                    <td width='40%'>Session 6<br>Speech and Language Processing-2<br>(NCU E6-B518)</td>
                    <td width='40%'>AI Tutorial IV-2<br>(NCU E6-B520)</td>
                </tr>

                <tr>
                    <td>17:00 – 17:10</td>
                    <td colspan="2"><b>Closing Ceremony</b></td>
                </tr>

            </table>

        </div>

        <div class='part' style='margin-top:30px;'>
            <h3 id='session-top'>Session 1 <br> <b>Speech and Language Processing – 1</b></h3>
            <h3>Time: Friday, October 15, 2021, 10:30 -12:30</h3>

            <div class='session-item'>
                <h4>
                    10:30-10:50<br>
                    <b>Universal Recurrent Neural Network Grammar</b>
                </h4>

                <p><I>Chinmay Choudhary and Colm O'riordan</I></p>

            </div>

            <div class='session-item'>
                <h4>
                    10:50-11:10<br>
                    <b>Learning to Find Translation of Grammar Patterns in Parallel Corpus</b>
                </h4>

                <p><I>Kai-Wen Tuan, Yi-Jyun Chen, Yi-Chien Lin, Chun-Ho Kwok, Hai-Lun Tu and Jason S. Chang</I></p>

            </div>

            <div class='session-item'>
                <h4>
                    11:10-11:30<br>
                    <b>Chinese Medical Speech Recognition with Punctuated Hypothesis</b>
                </h4>

                <p><I>Sheng-Luen Chung, Jin-Huan Fan and Hsien-Wei Ting</I></p>

            </div>

            <div class='session-item'>
                <h4>
                    11:30-11:50<br>
                    <b>Data centric approach to Chinese Medical Speech Recognition</b>
                </h4>

                <p><I>Sheng-Luen Chung, Yi-Shiuan Li and Hsien-Wei Ting</I></p>

            </div>

            <div class='session-item'>
                <h4>
                    11:50-12:10<br>
                    <b>A Preliminary Study on Environmental Sound Classification Leveraging Large-Scale Pretrained Model and Semi-Supervised Learning</b>
                </h4>

                <p><I>You-Sheng Tsao, Tien-Hong Lo, Jiun-Ting Li, Shi-Yan Weng and Berlin Chen</I></p>

            </div>

            <div class='session-item'>
                <h4>
                    12:10-12:30<br>
                    <b>Incorporating Speaker Embedding and Post-Filter Network for Improving Speaker Similarity of Personalized Speech Synthesis System</b>
                </h4>

                <p><I>Sheng-Yao Wang and Yi-Chin Huang</I></p>

            </div>

        </div>

        <div class='part' style='margin-top:30px;'>
            <h3 id='session-top'>Session 2<br> <b>Information Retrieval and Text Mining</b></h3>
            <h3>Time: Friday, October 15, 2021, 13:30 -15:00</h3>

            <div class='session-item'>
                <h4>
                    13:30-13:40<br>
                    <b>A BERT-based Siamese-structured Retrieval Model</b>
                </h4>

                <p><I>Hung-Yun Chiang and Kuan-Yu Chen</I></p>

            </div>

            <div class='session-item'>
                <h4>
                    13:40-13:50<br>
                    <b>AI Clerk Platform : Information Extraction DIY Platform</b>
                </h4>

                <p><I>Ru-Yng Chang, Wen-Lun Chen and Cheng-Ju Kao</I></p>

            </div>

            <div class='session-item'>
                <h4>
                    13:50-14:00<br>
                    <b>A Survey of Approaches to Automatic Question Generation：from 2019 to Early 2021</b>
                </h4>

                <p><I>Chao-Yi Lu and Sin-En Lu</I></p>

            </div>

            <div class='session-item'>
                <h4>
                    14:00-14:10<br>
                    <b>Hidden Advertorial Detection on Social Media in Chinese</b>
                </h4>

                <p><I>Meng-Ching Ho, Ching-Yun Chuang, Yi-Chun Hsu and Yu-Yun Chang</I></p>

            </div>

            <div class='session-item'>
                <h4>
                    14:10-14:20<br>
                    <b>Improved Text Classification of Long-term Care Materials</b>
                </h4>

                <p><I>Yi Fan Chiang, Chi-Ling Lee, Heng-Chia Liao, Yi-Ting Tsai and Yu-Yun Chang</I></p>

            </div>

            <div class='session-item'>
                <h4>
                    14:20-14:30<br>
                    <b>Keyword-centered Collocating Topic Analysis</b>
                </h4>

                <p><I>Yu-Lin Chang, Yongfu Liao, Po-Ya Angela Wang, Mao-Chang Ku and Shu-Kai Hsieh</I></p>

            </div>

            <div class='session-item'>
                <h4>
                    14:30-14:40<br>
                    <b>Extracting Academic Senses: Towards An Academic Writer's Dictionary</b>
                </h4>

                <p><I>Hsin-Yun Chung, Li-Kuang Chen and Jason S Chang </I></p>

            </div>

            <div class='session-item'>
                <h4>
                    14:40-14:50<br>
                    <b>Exploring the Integration of E2E ASR and Pronunciation Modeling for English Mispronunciation Detection</b>
                </h4>

                <p><I>Hsin-Wei Wang, Bi-Cheng Yan, Yung-Chang Hsu and Berlin Chen</I></p>

            </div>

        </div>

        <div class='part' style='margin-top:30px;'>
            <h3 id='session-top'>Session 3<br> <b>Best Paper Candidates</b></h3>
            <h3>Time: Friday, October 15, 2021, 15:30 -17:30</h3>

            <div class='session-item'>
                <h4>
                    15:30-15:50<br>
                    <b>Mining Commonsense and Domain Knowledge from Math Word Problems</b>
                </h4>

                <p><I>Shih-Hung Tsai, Chao-Chun Liang, Hsin-Min Wang and Keh-Yih Su</I></p>

            </div>

            <div class='session-item'>
                <h4>
                    15:50-16:10<br>
                    <b>MMTL: The Meta Multi-Task Learning for Aspect Category Sentiment Analysis</b>
                </h4>

                <p><I>Guan-Yuan Chen and Ya-Fen Yeh</I></p>

            </div>

            <div class='session-item'>
                <h4>
                    16:10-16:30<br>
                    <b>Using Valence and Arousal-infused Bi-LSTM for Sentiment Analysis in Social Media Product Reviews</b>
                </h4>

                <p><I>Yu-Ya Cheng, Wen-Chao Yeh, Yan-Ming Chen and Yung-Chun Chang</I></p>

            </div>

            <div class='session-item'>
                <h4>
                    16:30-16:50<br>
                    <b>Unsupervised Multi-document Summarization for News Corpus with Key Synonyms and Contextual Embeddings</b>
                </h4>

                <p><I>Yen-Hao Huang, Ratana Pornvattanavichai, Fernando Henrique Calderon Alvarado and Yi-Shin Chen</I></p>

            </div>

            <div class='session-item'>
                <h4>
                    16:50-17:10<br>
                    <b>Integrated Semantic and Phonetic Post-correction for Chinese Speech Recognition</b>
                </h4>

                <p><I>Yi-Chang Chen, Chun-Yen Cheng, Chien-An Chen, Ming-Chieh Sung and Yi-Ren Yeh </I></p>

            </div>

            <div class='session-item'>
                <h4>
                    17:10-17:30<br>
                    <b>Employing Low-Pass Filtered Temporal Speech Features for the Training of Ideal Ratio Mask in Speech Enhancement</b>
                </h4>

                <p><I>Yan-Tong Chen, Zi-Qiang Lin and Jeih-Weih Hung</I></p>

            </div>

        </div>

        <div class='part' style='margin-top:30px;'>
            <h3 id='session-top'>Session 4<br> <b>Sentiment Analysis and Social Media</b></h3>
            <h3>Time: Saturday, October 16, 2021, 10:20 -12:20</h3>

            <div class='session-item'>
                <h4>
                    10:20-10:40<br>
                    <b>A Flexible and Extensible Framework for Multiple Answer Modes Question Answering</b>
                </h4>

                <p><I>Cheng-Chung Fan, Chia-Chih Kuo, Shang-Bao Luo, Pei-Jun Liao, Kuang-Yu Chang, Chiao-Wei Hsu, Meng-Tse Wu, Shih-Hong Tsai, Tzu-Man Wu, Aleksandra Smolka, Chao-Chun Liang, Hsin-Min Wang, Kuan-Yu Chen, Yu Tsao and Keh-Yih Su </I></p>

            </div>

            <div class='session-item'>
                <h4>
                    10:40-11:00<br>
                    <b>Aspect-Based Sentiment Analysis and Singer Name Entity Recognition using Parameter Generation Network Based Transfer Learning</b>
                </h4>

                <p><I>Hsiao-Wen Tseng, Chia-Hui Chang and Hsiu-Min Chuang</I></p>

            </div>

            <div class='session-item'>
                <h4>
                    11:00-11:20<br>
                    <b>Aggregating User-Centric and Post-Centric Sentiments from Social Media for Topical Stance Prediction</b>
                </h4>

                <p><I>Jenq-Haur Wang and Kaun-Ting Chen</I></p>

            </div>

            <div class='session-item'>
                <h4>
                    11:20-11:40<br>
                    <b>What confuses BERT? Linguistic Evaluation of Sentiment Analysis on Telecom Customer Opinion</b>
                </h4>

                <p><I>Cing-Fang Shih, Yu-Hsiang Tseng, Ching-Wen Yang, Pin-Er Chen, Hsin-Yu Chou, Lian-Hui Tan, Tzu-Ju Lin, Chun-Wei Wang and Shu-Kai Hsieh</I></p>

            </div>

            <div class='session-item'>
                <h4>
                    11:40-12:00<br>
                    <b>A Corpus for Dimensional Sentiment Classification on YouTube Streaming Service</b>
                </h4>

                <p><I>Ching-Wen Hsu, Chun-Lin Chou, Hsuan Liu and Jheng-Long Wu</I></p>

            </div>

            <div class='session-item'>
                <h4>
                    12:00-12:20<br>
                    <b>A Study on Using Transfer Learning to Improve BERT Model for Emotional Classification of Chinese Lyrics</b>
                </h4>

                <p><I>Jia-Yi Liao, Ya-Hsuan Lin, Kuan-Cheng Lin and Jia-Wei Chang</I></p>

            </div>

        </div>

        <div class='part' style='margin-top:30px;'>
            <h3 id='session-top'>Shared Task <br> <b>Dimensional Sentiment Analysis for Education Texts</b></h3>
            <h3>Time: Saturday, October 16, 2021, 12:50 -13:30</h3>

            <div class='session-item'>
                <h4>
                    12:50 - 13:00<br>
                    <b>ROCLING-2021 Shared Task: Dimensional Sentiment Analysis for Educational Texts</b>
                </h4>

                <p><I>Liang-Chih Yu, Jin Wang, Bo Peng and Chu-Ren Huang</I></p>

            </div>

            <div class='session-item'>
                <h4>
                    13:00 - 13:05<br>
                    <b>ntust-nlp-1 at ROCLING-2021 Shared Task: Educational Texts Dimensional Sentiment Analysis using Pretrained Language Models</b>
                </h4>

                <p><I>Yi-Wei Wang, Wei-Zhe Chang, Bo-Han Fang, Yi-Chia Chen, Wei-Kai Huang and Kuan-Yu Chen</I></p>

            </div>

            <div class='session-item'>
                <h4>
                    13:05 - 13:10<br>
                    <b>ntust-nlp-2 at ROCLING-2021 Shared Task: BERT-Based Semantic Analyzer With Word-Level Information</b>
                </h4>

                <p><I>Ke-Han Lu and Kuan-Yu Chen</I></p>

            </div>

            <div class='session-item'>
                <h4>
                    13:10 - 13:15<br>
                    <b>NCU-NLP at ROCLING-2021 Shared Task: Using MacBERT Transformers for Dimensional Sentiment Analysis</b>
                </h4>

                <p><I>Man-Chen Hung, Chao-Yi Chen, Pin-Jung Chen and Lung-Hao Lee</I></p>

            </div>

            <div class='session-item'>
                <h4>
                    13:15 - 13:20<br>
                    <b>SCUDS at ROCLING-2021 Shared Task: Using Pretrained Model for Dimensional Sentiment Analysis Based on Sample Expansion Method</b>
                </h4>

                <p><I>Hsiao-Shih Chen, Pin-Chiung Chen, Shao-Cheng Huang, Yu-Cheng Chiu and Jheng-Long Wu</I></p>

            </div>

            <div class='session-item'>
                <h4>
                    13:20 - 13:25<br>
                    <b>SoochowDS at ROCLING-2021 Shared Task: Text Sentiment Analysis Using BERT and LSTM</b>
                </h4>

                <p><I>Ruei-Cyuan Su, Sing-Seong Chong, Tzu-En Su and Ming-Hsiang Su</I></p>

            </div>

            <div class='session-item'>
                <h4>
                    13:25 - 13:30<br>
                    <b>CYUT at ROCLING-2021 Shared Task: Based on BERT and MacBERT</b>
                </h4>

                <p><I>Xie-Sheng Hong and Shih-Hung Wu</I></p>

            </div>

        </div>

        <div class='part' style='margin-top:30px;'>
            <h3 id='session-top'>Session 5<br> <b>Applications</b></h3>
            <h3>Time: Saturday, October 16, 2021, 13:30 -15:00</h3>

            <div class='session-item'>
                <h4>
                    13:30-13:40<br>
                    <b>Nested Named Entity Recognition for Chinese Electronic Health Records with QA-based Sequence Labeling</b>
                </h4>

                <p><I>Yu-Lun Chiang, Chih-Hao Lin, Cheng-Lung Sung and Keh-Yih Su </I></p>

            </div>

            <div class='session-item'>
                <h4>
                    13:40-13:50<br>
                    <b>A Study on Contextualized Language Modeling for Machine Reading Comprehension</b>
                </h4>

                <p><I>Chin-Ying Wu, Yung-Chang Hsu and Berlin Chen</I></p>

            </div>

            <div class='session-item'>
                <h4>
                    13:50-14:00<br>
                    <b>Discussion on the Relationship Between Elders’ Daily Conversations and Cognitive Executive Function: Using Word Vectors and Regression Models</b>
                </h4>

                <p><I>Ming-Hsiang Su, Yu-An Ko and Man-Ying Wang</I></p>

            </div>

            <div class='session-item'>
                <h4>
                    14:00-14:10<br>
                    <b>Home Appliance Review Research Via Adversarial Reptile</b>
                </h4>

                <p><I>Tai-Jung Kan, Chia-Hui Chang and Hsiu-Min Chuang</I></p>

            </div>

            <div class='session-item'>
                <h4>
                    14:10-14:20<br>
                    <b>Numerical Relation Detection in Financial Tweets using Dependency-aware Deep Neural Network</b>
                </h4>

                <p><I>Yu-Chi Liang, Min-Chen Chen, Wen-Chao Yeh and Yung-Chun Chang</I></p>

            </div>

            <div class='session-item'>
                <h4>
                    14:20-14:30<br>
                    <b>Incorporating Domain Knowledge into Language Transformers for Multi-Label Classification of Chinese Medical Questions</b>
                </h4>

                <p><I>Po-Han Chen, Yu-Xiang Zeng and Lung-Hao Lee</I></p>

            </div>
            
            <div class='session-item'>
                <h4>
                    14:30-14:40<br>
                    <b>Confiscation Detection of Criminal Judgment Using Text Classification Approach</b>
                </h4>

                <p><I>Hsuan-Tzu Shih, Yu-Cheng Chiu, Hsiao-Shih Chen and Jheng-Long Wu</I></p>

            </div>

            <div class='session-item'>
                <h4>
                    14:40-14:50<br>
                    <b>Discussion on Domain Generalization in the Cross-Device Speaker Verification System</b>
                </h4>

                <p><I>Wei-Ting Lin, Yu-Jia Zhang, Chia-Ping Chen, Chung-Li Lu and Bo-Cheng Chan</I></p>

            </div>

            <div class='session-item'>
                <h4>
                    14:50-15:00<br>
                    <b>Data Augmentation Technology for Dysarthria Assistive Systems</b>
                </h4>

                <p><I>Wei-Chung Chu, Ying-Hsiu Hung, Wei-Zhong Zheng and Ying-Hui Lai </I></p>

            </div>

        </div>

        <div class='part' style='margin-top:30px;'>
            <h3 id='session-top'>Session 6<br> <b>Speech and Language Processing – 2</b></h3>
            <h3>Time: Saturday, October 16, 2021, 15:30 -17:00</h3>

            <div class='session-item'>
                <h4>
                    15:30-15:40<br>
                    <b>Predicting Elders' Cognitive Flexibility From Their Language Use</b>
                </h4>

                <p><I>Man-Ying Wang, Yu-an Ko, Chin-Lan Huang, Jyun-Hong Chen and Te-Tien Ting </I></p>

            </div>

            <div class='session-item'>
                <h4>
                    15:40-15:50<br>
                    <b>Improve Chit-Chat and QA Sentence Classification in User Messages of Dialogue System using Dialogue Act Embedding</b>
                </h4>

                <p><I>Chi Hsiang Chao, Xi Jie Hou and Yu Ching Chiu</I></p>

            </div>

            <div class='session-item'>
                <h4>
                    15:50-16:00<br>
                    <b>Automatic Extraction of English Grammar Pattern Correction Rules</b>
                </h4>

                <p><I>Kuan-Yu Shen, Yi-Chien Lin and Jason S. Chang</I></p>

            </div>

            <div class='session-item'>
                <h4>
                    16:00-16:10 <br>
                    <b>Multi-Label Classification of Chinese Humor Texts Using Hypergraph Attention Networks</b>
                </h4>

                <p><I>Hao-Chuan Kao, Man-Chen Hung, Lung-Hao Lee and Yuen-Hsien Tseng</I></p>

            </div>

            <div class='session-item'>
                <h4>
                    16:10-16:20<br>
                    <b>Generative Adversarial Networks based on Mixed-Attentions for Citation Intent Classification in Scientific Publications</b>
                </h4>

                <p><I>Yuh-Shyang Wang, Chao-Yi Chen and Lung-Hao Lee</I></p>

            </div>

            <div class='session-item'>
                <h4>
                    16:20-16:30<br>
                    <b>Identify Bilingual Patterns and Phrases from a Bilingual Sentence Pair</b>
                </h4>

                <p><I>Yi-Jyun Chen, Hsin-Yun Chung and Jason S. Chang</I></p>

            </div>

            <div class='session-item'>
                <h4>
                    16:30-16:40<br>
                    <b>Speech Emotion Recognition Based on CNN+LSTM Model</b>
                </h4>

                <p><I>Wei Mou, Pei-Hsuan Shen, Chu-Yun Chu, Yu-Cheng Chiu, Tsung-Hsien Yang and Ming-Hsiang Su</I></p>

            </div>

            <div class='session-item'>
                <h4>
                    16:40-16:50<br>
                    <b>Exploiting Low-Resource Code-Switching Data to Mandarin-English Speech Recognition Systems</b>
                </h4>

                <p><I>Hou-An Lin and Chia-Ping Chen</I></p>

            </div>

            <div class='session-item'>
                <h4>
                    16:50-17:00<br>
                    <b>RCRNN-based Sound Event Detection System with Specific Speech Resolution</b>
                </h4>

                <p><I>ChenSung-Jen Huang, Yih-Wen Wang, Chia-Ping Chen, Chung-Li Lu and Bo-Cheng Chan</I></p>

            </div>

        </div>


    </div>


    <!-- ============================================================================ -->

    <div class="registration" id="registration">
        <h1>Registration</h1>

        <div class='part' id='reg-table-1' style="padding-bottom: 0;">
            <table>
                <tr>
                    <th>Type</th>
                    <th colspan="2">Early Registration<br>(Before Sep. 15, 2021)</th>
                    <th colspan="2">Late Registration<br>(Sep. 16 - Oct. 5, 2021)</th>
                    <th colspan="2">On-Site Registration<br> (Oct. 15-16, 2021)</th>
                </tr>

                <tr>
                    <td>Registration Category</td>
                    <td>Regular</td>
                    <td>Student</td>
                    <td>Regular</td>
                    <td>Student</td>
                    <td>Regular</td>
                    <td>Student</td>
                </tr>

                <tr>
                    <td>ACLCLP Member</td>
                    <td>NT$2,500 </td>
                    <td>NT$500</td>
                    <td>NT$3,000</td>
                    <td>NT$800</td>
                    <td>NT$3,500</td>
                    <td>NT$1,000</td>
                </tr>

                <tr>
                    <td>ACLCLP Non-Member</td>
                    <td>NT$3,500 </td>
                    <td>NT$1,000</td>
                    <td>NT$4,000</td>
                    <td>NT$1,300</td>
                    <td>NT$4,500</td>
                    <td>NT$1,500</td>
                </tr>

                <tr>
                    <td>贊助單位/Sponsors</td>
                    <td colspan="6">免費/Free</td>
                </tr>

                <tr>
                    <td>ACLCLP會員會費</td>
                    <td colspan="6">一般會員：NT$1,000元；學生會員：NT$500元</td>
                </tr>

            </table>

        </div>

        <div class='part' id='reg-table-2' style="padding-bottom: 0;">
            <table>
                <tr>
                    <th>Type</th>
                    <th colspan="2">Early Registration<br>(Before Sep.15, 2021)</th>
                </tr>

                <tr>
                    <td>Registration Category</td>
                    <td>Regular</td>
                    <td>Student</td>
                </tr>

                <tr>
                    <td>ACLCLP Member</td>
                    <td>NT$2,500 </td>
                    <td>NT$500</td>
                </tr>

                <tr>
                    <td>ACLCLP Non-Member</td>
                    <td>NT$3,500 </td>
                    <td>NT$1,000</td>
                </tr>

                <tr>
                    <th>Type</th>
                    <th colspan="2">Late Registration<br>(Sep. 16 - Oct. 5, 2021)</th>
                </tr>

                <tr>
                    <td>Registration Category</td>
                    <td>Regular</td>
                    <td>Student</td>
                </tr>

                <tr>
                    <td>ACLCLP Member</td>
                    <td>NT$3,000</td>
                    <td>NT$800</td>
                </tr>

                <tr>
                    <td>ACLCLP Non-Member</td>
                    <td>NT$4,000</td>
                    <td>NT$1,300</td>

                </tr>

                <tr>
                    <th>Type</th>
                    <th colspan="2">On-Site Registration<br>(Oct. 15-16, 2021)</th>
                </tr>

                <tr>
                    <td>Registration Category</td>
                    <td>Regular</td>
                    <td>Student</td>
                </tr>

                <tr>
                    <td>ACLCLP Member</td>
                    <td>NT$3,500</td>
                    <td>NT$1,000</td>
                </tr>

                <tr>
                    <td>ACLCLP Non-Member</td>
                    <td>NT$4,500</td>
                    <td>NT$1,500</td>
                </tr>

                <tr>
                    <td>贊助單位/Sponsors</td>
                    <td colspan="2">免費/Free</td>
                </tr>

                <tr>
                    <td>ACLCLP會員會費</td>
                    <td colspan="2">一般會員：NT$1,000元；學生會員：NT$500元</td>
                </tr>

            </table>

        </div>

        <div class="part" style="padding-top: 30px ;">
            <p style="text-align : center; font-size: 30px ;"><a href="https://conference.iis.sinica.edu.tw/surl/rocling2021/reg" target="_blank" title="uninstructed">Click here to Register</a></p>
        </div>

        <div class="part">
            <h2>Registration Fees</h2>
            <p>附註說明：</p>
            <div class="list">
                <ol>
                    <li><p style="color: red;">每篇會議論文的發表至少要繳交一筆「一般人士」報名費。</p></li>
                    <li>報名費一經繳費後恕不接受退費，報名費收據將連同會議資料於10/8一併郵寄。</li>
                    <li><a href="https://www.google.com/url?q=http://www.aclclp.org.tw/member.php&source=gmail-html&ust=1629447940737000&usg=AFQjCNFE6hIwLcwohQGMPvvfiyCh-VNe-g" target="_blank" title="uninstructed">ACLCLP Member</a>
                        為「<a href="https://www.google.com/url?q=http://www.aclclp.org.tw/index_c.php&source=gmail-html&ust=1629447940737000&usg=AFQjCNEVTHg6PmFNq_r-QE9uIEyow1Pl7g" target="_blank" title="uninstructed">中華民國計算語言學學會</a>」
                        之<b>有效會員</b>。</li>
                    <li>本年度<b>尚未繳交年費之舊會員或失效之會員</b>，報名之與會身份/Category請勾選「….(會員+會費)」，<b><p style="color: red;display: inline;">勿需再申請入會</p></b>。</li>
                    <li><b>非會員欲同時申請入會者</b>，請先至學會網頁之「會員專區」申請加入會員；報名之「與會身份/Category」請勾選「….(會員+會費)」。
                        (<a href="https://www.google.com/url?q=http://www.aclclp.org.tw/member/index.php&source=gmail-html&ust=1629447940737000&usg=AFQjCNGk4tOyMTrVXiaptjL5ov5IAB_2tw" target="_blank" title="uninstructed">前往會員專區</a>)</li>
                    <li>以「學生新會員」及「學生非會員」身份報名者，請於報名時上傳學生身份證明。</li>
                    <li>贊助單位敬請於<b><p style="color: red;display: inline;">10/5</p></b>前完成線上報名手續。</li>
                    <li>報名完成後，若需更正個人資料，請於10/5前以Email方式聯絡大會。</li>                    
                </ol>
            </div>
        </div>

        <div class="part">
            <h2>Registration Details：</h2>
            <div class="list">
                <ol>
                    <li><b><p style="color: red;display: inline;">One Regular registration can cover a maximum of One Paper. Student registration can NOT cover paper.</p></b></li>
                    <li>Registration fees are non-refundable.</li>
                    <li>International registrants have to pay by credit card only (Visa or Master Card). All the conference registration payment will be charged in currency of New Taiwan dollars.</li>
                    <li>For “full-time Students”, please upload the image (or pdf) of student ID card. </li>
                </ol>
            </div>
        </div>

        <div class="part">
            <h2>報名及繳費期限/Important Dates for Registration：</h2>
            <div class="list">
                <ul>
                    <li>Early Registration-9/15(Wed)以前：報名費應於<b><p style="color: red;display: inline;">9/20(Mon)前</p></b>繳交。/Registration due by September 15. Payment must be received before <b><p style="color: red;display: inline;">September 20</p></b>.</li>
                    <li>Late Registration-9/16(Thu)~10/5(Tue)：報名費應於<b><p style="color: red;display: inline;">10/5(Tue)前</p></b>繳交。/Registration between September 16 to October 5. Payment must be received before <b><p style="color: red;display: inline;">October 5</p></b>.</li>
                    <li>On-Site Registration-10/6(Wed)線上報名截止，擬報名者請於10/15(Fri)線上報名。/ The registration site will be closed on October 6. </li>
                </ul>
            </div>
        </div>

        <div class="part">
            <h2>繳費方式/Methods of Payment：</h2>
            <div class="list">
                <ul>
                    <li>郵政劃撥/ Postal: 戶名：中華民國計算語言學學會，帳號：19166251。<br>
                        <p style="color: blue;display: inline;">(同一單位多位報名者可合併劃撥，請於劃撥通訊欄中註明您的「Registration ID」號碼)。</p></li>
                    <li>信用卡傳真/Fax credit card : Fax: 02-27881638, E-mail: <a href="mailto:aclclp@aclclp.org.tw">aclclp@aclclp.org.tw</a>。</li>
                    <li>線上刷卡繳費/credit card on-line。</li>
                </ul>
            </div>
        </div>

        <div class="part">
            <h2>註冊費事宜/ For registration inquiries, please contact：</h2>
            <div class="information">
                <p>
                    聯絡人：黃琪 小姐（中華民國計算語言學學會） (Miss Huang, ACLCLP）<br>
                    E-mail：<a href="mailto:aclclp@aclclp.org.tw">aclclp@aclclp.org.tw</a><br>
                    Phone Number: 02-27883799  Ext.1502<br>
                    Fax Number: 02-27881638<br>
                </p>
            </div>  
        </div>

    </div>
    
    <!-- ============================================================================ -->

    <div class="keynote" id="key_note">

        <div class='part'>

            <div class='intro_title'>
                <h2>NLP Keynote by Prof. Vincent Ng</h2>
            </div>

            <div class='introduction'>

                <div class='intro'>

                    <div class='intro_img'>
                        <img src="image/keynote/ng.jpg" alt="Vincent Ng (Ph.D., Cornell)">
                    </div>

                    <div class='intro_text'>
                        <h3 id='title'>Event Coreference Resolution: Successes and Future Challenges</h3>

                        <h3><b>Speaker: Prof. Vincent Ng</b><br>
                            Professor, The University of Texas at Dallas<br>
                            <i>Time:  Friday, October 15, 2021, 09:10 - 10:10</i><br></h3>

                        <h3><b>Session Chair: Liang-Chih Yu</b></h3>
                    </div>

                </div>

                <div class="BandA">

                    <h5>Biography</h5>
                    <p>Vincent Ng is a Professor in the Computer Science Department at the University of Texas at Dallas. He is also the director of the Machine Learning and Language Processing Laboratory in the Human Language Technology Research Institute at UT Dallas. He obtained his B.S. from Carnegie Mellon University and his Ph.D. from Cornell University. His research is in the area of Natural Language Processing, focusing on the development of computational methods for addressing key tasks in information extraction and discourse processing.</p>                    
                    
                    <h5>Abstract</h5>
                    <p>Recent years have seen a gradual shift of focus from entity-based tasks to event-based tasks in information extraction research. This talk will focus on event coreference resolution, the event-based counterpart of the notoriously difficult entity coreference resolution task. Specifically, I will examine the major milestones made in event coreference research since its inception more than two decades ago, including the recent successes of neural event coreference models and their limitations, and discuss possible ways to bring these models to the next level of performance.</p>                

                </div>
                
            </div>

        </div>

        <div class='part'>

            <div class='intro_title'>
                <h2>Speech Keynote by Dr. Jinyu Li</h2>
            </div>

            <div class='introduction'>

                <div class='intro'>

                    <div class='intro_img'>
                        <img src="image/keynote/Jinyu_Li.jpg" alt="Jinyu Li">
                    </div>

                    <div class='intro_text'>
                        <h3 id='title'>Advancing end-to-end automatic speech recognition</h3>

                        <h3><b>Speaker: Dr. Jinyu Li</b><br>
                            Partner Applied Scientist and Technical Lead,  Microsoft Corporation, Redmond, USA<br>
                            <i>Time:  Saturday, October 16, 2021, 09:00 - 10:00</i><br></h3>

                        <h3><b>Session Chair: Yu Tsao</b></h3>
                    </div>

                </div>

                <div class="BandA">

                    <h5>Biography</h5>
                    <p>Jinyu Li received the Ph.D. degree from Georgia Institute of Technology, Atlanta, in 2008. From 2000 to 2003, he was a Researcher in the Intel China Research Center and Research Manager in iFlytek, China. Currently, he is a Partner Applied Scientist and Technical Lead in Microsoft Corporation, Redmond, USA. He leads a team to design and improve speech modeling algorithms and technologies that ensure industry state-of-the-art speech recognition accuracy for Microsoft.His major research interests cover several topics in speech recognition, including end-to-end modeling, deep learning, noise robustness, etc. He is the leading author of the book "Robust Automatic Speech Recognition -- A Bridge to Practical Applications", Academic Press, Oct, 2015. He is the member of IEEE Speech and Language Processing Technical Committee since 2017. He also served as the associate editor of IEEE/ACM Transactions on Audio, Speech and Language Processing from 2015 to 2020.</p>                    
                    <h5>Abstract</h5>
                    <p>Recently, the speech community is seeing a significant trend of moving from deep neural network based hybrid modeling to end-to-end (E2E) modeling for automatic speech recognition (ASR). While E2E models achieve the state-of-the-art results in most benchmarks in terms of ASR accuracy, hybrid models still dominate the commercial ASR systems at current time. There are lots of practical factors that affect the production model deployment decision. Traditional hybrid models, being optimized for production for decades, are usually good at these factors. Without providing excellent solutions to all these factors, it is hard for E2E models to be widely commercialized.
                        In this talk, I will overview the recent advances in E2E models with the focus on technologies addressing those challenges from the perspective of industry. Specificly, I will describe methods of 1) building high-accuracy low-latency E2E models, 2) building a single E2E model to serve all multilingual users, 3) customizing and adapting E2E models to a new domain 4) extending E2E models for multi-talker ASR etc. Finally, I will conclude the talk with some challenges we should address in the future.
                    </p>  
                </div>
                
            </div>

        </div>
   
    </div>

    <!-- ============================================================================ -->

    <div class='Tutorials' id='tutor'>
        <!-- <h1>Tutorials</h1> -->

        <div class='part' style='margin-top:30px;'>
            <h2>AI Tutorial I</h2>
            <h2><b>Speech enhancement (from signal processing to machine learning solutions)<br> and its applications for assistive hearing technology</b></h2>

            <h3>Time: Friday, October 15, 2021, 10:30-12:30</h3>
            <h3>Speakers: Yu Tsao (曹昱), Syu Siang Wang  (王緒翔)</h3>

            <h4>Abstract</h4>

            <p>
                The proportional increase in the elderly population and the inappropriate use of portable audio devices have led to a rapid increase in incidents of hearing loss. Untreated hearing loss can cause feelings of loneliness and isolation in the elderly and may lead to learning difficulties in students. Over the past few years, our group has investigated the application of machine learning and signal processing algorithms in FM assistive hearing systems, hearing aids, and cochlear implants (CIs) to improve speech communication in hearing-impaired patients and the subsequent enhancement in their quality of life. The tremendous progress of hearing-assistive technologies has enabled many hearing-loss recipients to enjoy a high level of speech perception in quiet conditions. However, speech intelligibility in noisy conditions still remains a challenge.
            </p>
            <p>
                Meanwhile, real-world environments always contain stationary and/or time-varying noises that are collected together with speech signals by recording devices. These received signals inevitably degrade the performance of human-human and human-machine interfaces and have been attracted significant attention over the past years. To address this issue, an important front-end speech process, namely speech enhancement, is exploited to improve voice quality and intelligibility from noise-deteriorated clean speech. In addition, speech enhancement techniques extracting clean components from noisy input are combined with various applications including hearing assistive devices. In this tutorial, we are going to introduce conventional speech enhancement methods, its idea, concepts, and performances, and following with deep-learning denoising approaches. The applications for assistive hearing technology are then provided in the rest of the course.
            </p>

        </div>

        <div class='part'>
            <h2 id='AIT'>AI Tutorial II </h2>
            <h2><b>深度學習在教育科技上的應用 <br>（學術詞彙片語、雙語對應、文法推導、<br>文法改錯、反向詞典、定義分類與導引詞）</b></h2>

            <h3>Time: Friday, October 15, 2021, 13:30-15:00, 15:30-17:00</h3>
            <h3>Speakers: 張俊盛、楊謦瑜、吳鑑城、白明弘、杜海倫、陳志杰、段凱文</h3>

            <h4>Abstract</h4>

            <div class='list'>
                <ul>
                    <li>學術詞彙+片語：如何延伸 Paquot (2000) 的 Academic Keyword List，產生定義、翻譯、例句、片語。</li>
                    <li>雙語詞彙、文法對應：如何改善前世代統計式片語機器翻譯的詞彙對應、片語對應，文法規則對應。</li>
                    <li>語言學搜尋引擎：如何利用 Google Web 1T 和 UDN 新聞語料庫，搜尋英文、中文的 Pattern Grammar 的文法規則 (Hunston 2000)</li>
                    <li>文法改錯：如何突破 Grammarly 的限制，處理搭配錯誤。</li>
                    <li>反向詞典：產生詞典語意（英文、中文）定義的詞彙內嵌，以及相關英文寫作應用。</li>
                    <li>辭典定義分類：產生詞典語意（英文、中文）定義的語意分類，可以將劍橋英漢辭典和羅氏主題詞典（Roget's Thesaurus）、維基百科的 Wikidata 連結起來。</li>
                    <li>辭典導引詞：用辭典定義分類技術，產生兩組合理，一致性高的歧異詞導引詞：以劍橋英漢線上辭典為例。</li>
                </ul>
            </div>

        </div>

        <div class='part'>
            <h2 id='AIT'>AI Tutorial III </h2>
            <h2><b>Deep Learning Development Pipeline on CHT AI Platform <br>
                – Using Speaker Verification as an Example</b></h2>

            <h3>Time: Saturday, October 16, 2021, 12:50-13:30</h3>
            <h3>Speaker: 黃梓翔</h3>

            <h4>Abstract</h4>

            <div class='list'>
                <ul>
                    <li>介紹 AI PaaS 機器學習平台的功能</li>
                    <li>透過 AI PaaS ，向學員展示聲紋辨識的模型生命週期流程，包括聲紋特徵擷取模型的開發、訓練與部署</li>
                    <li>啟動展示介面，向學員展示「聲紋辨識」的應用情境</li>
                </ul>
            </div>
            

        </div>

        <div class='part'>
            <h2 id='AIT'>AI Tutorial IV </h2>
            <h2><b>語音標記及建模工具套件 (Speech Labeling and Modeling ToolKit, SLMTK)<br>於個人化文字轉語音系統之建立 </b></h2>

            <h3>Time: Saturday, October 16, 2021, 13:30-15:00, 15:30-17:00</h3>
            <h3>Speaker: 江振宇</h3>

            <h4>Abstract</h4>

            <p>SLMTK 為 Speech Labeling and Modeling Toolkit 的縮寫，由國立臺北大學通訊工程學系「語音暨多媒體訊號處理實驗室」開發，SLMTK 是一套可快速且自動化將語音及文本標記成可以建立韻律產生模型以及語音合成模型的語音標記工具，韻律標記的標準以及語音標記格式皆已制訂於套件內，方便分析以及建模使用，亦可以建立出基礎的韻律產生模型以及語音合成模型。另外，SLMTK 產生的語言、語音、以及韻律標記，亦可為語言語音研究者提供具有意義的輔助標記。</p>
            <p>目前 SLMTK 已在多個語料庫上進行實驗，並已有商用產品使用 SLMTK 建立 TTS (text-to-speech) 應用。SLMTK 亦支援科技部 “研發整合漸凍症病友智慧溝通系統-成果加值及落地應用” (MOST-109-3011-F-011-001-) 之 “子計畫二：回聲計畫-漸凍症病友文字轉語音系統之建立”，與「中華民國運動神經元疾病病友協會」以及「聲帆股份有限公司」合作，目前已建立 20 位漸凍症病友客製化的文字轉語音系統，能在輔具上輸入文字後，以病友自己特有的聲音發聲。</p>
            <p>SLMTK 將用於「中華民國運動神經元疾病病友協會」的 Voicebank 活動，將大量處理語音捐獻者的語音，以協助改善或建立病友的客製化 TTS。目前 SLMTK 支援純中文以及中英夾雜的語音處理，未來將有支援台語以及客語的延伸模組。本 Tutorial 將會分成兩部分講述： </p>

            <div class='AI3'>
                
                <div id='AI3-1'>
                    <table>
                        <tr>
                            <th>Part I： 文字轉語音系統 overview</th>
                            <th>Part II： 使用 SLMTK 建立客製化文字轉語音系統</th>
                        </tr>

                        <tr>
                            <td style='vertical-align:text-top;'>
                                <ol style='text-align: left; vertical-align:text-top;'>
                                    <li>TTS as a mapping function</li>
                                    <li>A Brief Review of Speech Generation Process</li>
                                    <li>Information Extracted from Input Text</li>
                                    <li>Segmental/Speech Analysis</li>
                                    <li>Syllable Structure of Mandarin</li>
                                    <li>Speech Production</li>
                                    <li>Prosody - Supra-segmental Analysis</li>
                                    <li>Prosody and Syntax</li>
                                    <li>TTS Pipelines</li>
                                </ol>
                            </td>

                            <td style='vertical-align:text-top;'>
                                <ol style='text-align: left; '>
                                    <li>SLMTK in Brief</li>
                                    <li>Text Analysis</li>
                                    <li>Speech Segmentation</li>
                                    <li>Prosody-Linguistic Feature Integration</li>
                                    <li>Prosody Labeler</li>
                                    <li>Training of TTS Models</li>
                                </ol>
                            </td>
                        </tr>

                    </table>
                </div>

                <div id='AI3-2'>

                    <table>
                        <tr>
                            <th>Part I： 文字轉語音系統 overview</th>
                        </tr>

                        <tr>
                            <td style='vertical-align:text-top;'>
                                <ol style='text-align: left; vertical-align:text-top;'>
                                    <li>TTS as a mapping function</li>
                                    <li>A Brief Review of Speech Generation Process</li>
                                    <li>Information Extracted from Input Text</li>
                                    <li>Segmental/Speech Analysis</li>
                                    <li>Syllable Structure of Mandarin</li>
                                    <li>Speech Production</li>
                                    <li>Prosody - Supra-segmental Analysis</li>
                                    <li>Prosody and Syntax</li>
                                    <li>TTS Pipelines</li>
                                </ol>
                            </td>
                        </tr>

                        <tr>
                            <th>Part II： 使用 SLMTK 建立客製化文字轉語音系統</th>
                        </tr>

                        <tr>
                            <td style='vertical-align:text-top;'>
                                <ol style='text-align: left; '>
                                    <li>SLMTK in Brief</li>
                                    <li>Text Analysis</li>
                                    <li>Speech Segmentation</li>
                                    <li>Prosody-Linguistic Feature Integration</li>
                                    <li>Prosody Labeler</li>
                                    <li>Training of TTS Models</li>
                                </ol>
                            </td>
                        </tr>

                    </table>
                </div>

            </div>

        </div>

       

    </div>


    <!-- ============================================================================ -->

    <div class="special_session" id='special'>
        <h1>Special Session</h1>

        <div class="session">
            <h2>大腦與語言<br>
                Special Session: Brain and Language
            </h2>
            <div class="people">
                <div class="author">
                    <img src="image/Special_Session/徐峻賢.jpg">
                    <p>
                        徐峻賢 Chun-hsien Hsu<br>
                        國立中央大學認知神經科學研究所<br>
                        Institute of Cognitive Neuroscience<br>
                        National Central University, Taiwan<br>
                        neurolang@g.ncu.edu.tw
                    </p>
                </div>

                <div class="author">
                    <img src="image/Special_Session/李佳穎.jpg">
                    <p>
                        李佳穎 Chia-ying Lee<br>
                        中央研究院語言學研究所<br>
                        Institute of Linguistics<br>
                        Academia Sinica, Taiwan<br>
                        chiaying@gate.sinica.edu.tw
                    </p>
                </div>

                <div class="author">
                    <img src="image/Special_Session/李佳霖.jpg">
                    <p>
                        李佳霖 Chia-lin Lee<br>
                        國立台灣大學語言學研究所<br>
                        Graduate Institute of Linguistics<br>
                        National Taiwan University, Taiwan<br>
                        chialinlee@ntu.edu.tw
                    </p>
                </div>
            </div>

            <div class="content">
                <h3>摘要</h3>
                <p>作為一門跨領域的科學研究項目，神經語言學擅長結合各種領域知識，主要包含腦科學、語言學理論、計算科學、認知心理學，以探討大腦如何處理人類語言。本次座談會希望將相關的研究成果回饋給科學研究社群，以鼓勵更多資訊科學、語言學領域的學者和研究生參與神經語言學的研究。本次座談會提到的語言參數來自各種不同的資源，包含中華民國計算語言學會出版的平衡語料庫、口語資料庫，以及研究者依照研究目的而建置的語料。這些資訊有助於實驗研究，以探索語言發展，以及探索一般正常母語使用者的大腦解讀語言結構的方式。徐峻賢會介紹基本的認知神經科學研究方法，以及使用腦磁圖技術研究構詞理論、口語理解的研究成果，並且分享以深度學習模型探討大腦活動特徵的研究方法。李佳穎將介紹結合行為測量、事件關聯腦電位進行詞彙知識、語言發展的研究成果，以實證研究澄清一般人對於中文的字型、字音結構常有的迷思，並且從語料庫進行語意多樣性的分析說明當前心理詞彙理論的轉變。李佳霖將分享人們處理意義的認知功能和其大腦機制，包含從語言使用的情境提取適當的語意訊息 （比如 “鋼琴” 要指涉音色、形狀、還是操作方式），以及老化造成的改變對於處理意義的認知功能之影響。
                </p>
                
                <h3>Abstract</h3>
                <p>Neurolinguistic is an interdisciplinary study that incorporates elements of neuroscience, linguistics, computational science, and cognitive psychology to aiming to explore how the brain processes human language. By presenting our research results to the science community, we hope to encourage future studies from researchers and graduate students in the areas of computational science and linguistics. The speech parameters mentioned in this symposium were gathered from distinct sources including Sinica Corpus and COSPRO & Toolkit published by the Association for Computational Linguistics and Chinese Language Processing, and customized databases that were built by researchers regarding their purposes of research. These data are beneficial to research studies aiming to explore topics in language development and language comprehension in native speakers. Dr. Chun-Hsien Hsu is going to introduce some basic research methods in cognitive neuroscience, and the research results of using Magnetoencephalography (MEG) to study morphosyntactic theories and speech comprehension. Dr. Hsu would also shares some approaches to employ deep learning models for studying the features of brain responses to language. Dr. Chia-yin Lee is going to talk about the use of combining behavioral testings and Event-Related Potential (ERP) in vocabulary knowledge and language development studies. Dr. Lee intends to clarify common misconceptions and myths about Chinese orthography and phonetic structures, and explain the current changes/shift in theories of mental lexicon through corpus analyses. Dr. Chia-Lin Lee is going to share with us about the cognitive functions and brain mechanisms involved in the processing of meaningful information, which includes the fetching of appropriate semantic meaning depending on the context of usage ( i.e. the concept of “piano” may comprise the sound of a piano, the shape of the instrument, and different ways to play it etc.), and the effect of aging on general cognitive function and semantic processes. 
                </p>

            </div>
        </div>

    </div>

    <!-- ============================================================================ -->
    
    <div class="sharetask" id="task">
        <h1>ROCLING 2021 Shared Task:</h1>
        <h3><br>Dimensional Sentiment Analysis for Educational Texts</h3>


        <div class="share_org">
            <h2>Organizers</h2>
            <div class="share_people">
                <div class="author">
                    <img src="image/share_task/Liang-Chih-Yu.jpg">
                    <p>
                        禹良治 Liang-Chih Yu<br>
                        元智大學資訊管理學系<br>
                        Department of Information Management<br>
                        Yuan Ze University, Taiwan<br>
                        lcyu@saturn.yzu.edu.tw
                    </p>
                </div>
                <div class="author">
                    <img src="image/share_task/Jin-Wang.jpg">
                    <p>
                        王津 Jin Wang<br>
                        雲南大學 信息學院<br>
                        School of Information Science & Engineering<br>
                        Yunnan University<br>
                        wangjin@ynu.edu.cn
                    </p>
                </div>
                <div class="author">
                    <img src="image/share_task/Peng.jpeg">
                    <p>
                        彭博 Bo Peng<br>
                        香港理工大學 中文及雙語學系<br>
                        The Department of Chinese and Bilingual Studies<br>
                        The Hong Kong Polytechnic University<br>
                    </p>
                </div>
                <div class="author">
                    <img src="image/share_task/Chu-Ren-Huang.jpg">
                    <p>
                        黃居仁 Chu-Ren Huang<br>
                        香港理工大學 中文及雙語學系<br>
                        The Department of Chinese and Bilingual Studies<br>
                        The Hong Kong Polytechnic University
                    </p>
                </div>

            </div>
        </div>

        
        <div class="part">
            <h2>I.&emsp;Background</h2>
            <p>Sentiment analysis has emerged as a leading technique to automatically identify affective information within texts. In sentiment analysis, affective states are generally represented using either categorical or dimensional approaches (Calvo and Kim, 2013). The categorical approach represents affective states as several discrete classes (e.g., positive, negative, neutral), while the dimensional approach represents affective states as continuous numerical values on multiple dimensions, such as valence-arousal (VA) space (Russell, 1980), as shown in Fig. 1. The valence represents the degree of pleasant and unpleasant (or positive and negative) feelings, and the arousal represents the degree of excitement and calm. Based on this two-dimensional representation, any affective state can be represented as a point in the VA coordinate plane by determining the degrees of valence and arousal of given words (Wei et al., 2011; Malandrakis et al., 2013; Wang et al., 2016; Du and Zhang, 2016; Wu et la., 2017; Yu et al., 2020) or texts (Kim et al., 2010; Paltoglou et al, 2013; Goel et la., 2017; Zhu et al., 2019; Wang et al., 2019; 2020).</p>
            <p>In 2016, we hosted a first dimensional sentiment analysis task for Chinese words (Yu et al., 2016b) at the 20th International Conference on Asian Language Processing (IALP 2016). In 2017, we extended this task to include both word- and phrase-level dimensional sentiment analysis (Yu et al., 2017). This year, we explore the sentence-level dimensional sentiment analysis task on educational texts (students’ self-evaluated comments).</p>
            <div class="f1"><img src="image/share_task/Figure1.png"></div>
            
        </div>

        <div class="part">
            <h2>II.&emsp;Task Description</h2>
            <p>Structured data such as attendance, homework completion and in-class participation have been extensively studied to predict students’ learning performance. Unstructured data, such as self- evaluation comments written by students, is also a useful data resource because it contains rich emotional information that can help illuminate the emotional states of students (Yu et al., 2018). Dimensional sentiment analysis is an effective technique to recognize the valence-arousal ratings from texts, indicating the degree from most negative to most positive for valence, and from most neutral low Valence IV Low-Arousal, Positive-Valence Tired calm to most excited for arousal.</p>
            <p>In this task, participants are asked to provide a real-valued score from 1 to 9 for both valence and arousal dimensions for each self-evaluation comment. The input format is “sentence_id, sentence”, and the output format is “sentence_id, vallence_rating, arousal_rating”. Below are the input/output formats of the example sentences.</p>
            <div class="example">
                <h3>Example 1:</h3>
                <p>&emsp; &emsp; &emsp;Input: 1, 今天教了許多以前沒有學過的東西，所以上起課來很新鮮</p>
                <p>&emsp; &emsp; &emsp;Output: 1, 6.8, 5.2</p>
            </div>
            <div class="example">
                <h3>Example 2:</h3>
                <p>&emsp; &emsp; &emsp;Input: 2, 覺得課程進度有點快，內容難以消化</p>
                <p>&emsp; &emsp; &emsp;Output: 2, 3.0, 4.0</p>
            </div>
            
        </div>

        <div class="part">
            <h2>III.&emsp;Data</h2>
            <p>Training set</p>
            <div class="list">
                <ul>
                    <li><a href="http://nlp.innobic.yzu.edu.tw/resources/cvaw.html" target="_blank" title="uninstructed">CVAW 4.0</a> : including 5,512 single words annotated with valence-arousal ratings (Yu et al., 2016a).</li>
                    <li><a href="http://nlp.innobic.yzu.edu.tw/resources/cvap.html" target="_blank" title="uninstructed">CVAP 2.0</a> : including 2,998 multi-word phrases annotated with valence-arousal ratings (Yu et al., 2017)</li>
                    <li><a href="http://nlp.innobic.yzu.edu.tw/resources/cvat.html" target="_blank" title="uninstructed">CVAT 2.0</a> : including 2,969 sentences annotated with valence-arousal ratings (Yu et al., 2016a).</li>
                </ul>
            </div>

            <p><br><a href="test.xlsx" target="_blank" title="uninstructed">Test set</a>： including 1,600 sentences about educational texts</p>
            
            <p><br>The policy of this shared task is an open test. Participating systems are allowed to use other publicly available data for this shared task, but the use of other data should be specified in the final technical report.</p>
        </div>

        <div class="part">
            <h2>IV.&emsp;Evaluation</h2>
            <p>The performance is evaluated by examining the difference between machine-predicted ratings and human-annotated ratings (valence and arousal are treated independently). The evaluation metrics include:</p>
            <div class="formula">
                <table class="for_tab">
                    <tr>
                        <td><p>Mean absolute error:</p></td>
                        <td><img src="image/share_task/mae.png"></td>
                    </tr>
                    <tr>
                        <td><p>Pearson correlation coefficient:</p></td>
                        <td><img src="image/share_task/pcc.png"></td>
                    </tr>
                </table>
            </div>
            <p>where A<sub>i</sub> denotes the human-annotated ratings, P<sub>i</sub> denotes the machine-predicted ratings, n is the number of test samples, A and P respectively denote the arithmetic mean of A and P, and σ is the
                standard deviation.</br></br>
            </p>
            <p>Scoring script:
                <a href="evaluation.zip" target="_blank" title="uninstructed">
                    Click here
                </a>
            </p>
        </div>

        <div class="part">
            <h2>V.&emsp;Important Dates</h2>
            
                <p>Registration:
                    <a href="https://docs.google.com/forms/d/e/1FAIpQLSe74D0A_sWAOKH_xtz9_uF7ws9G-cdF2gYiEm5YwONQOcctrA/viewform?vc=0&c=0&w=1&flr=0" target="_blank" title="uninstructed">
                        Click here
                    </a>
                </p>
             
            <div class="list">
                <ul>
                    <li>Release of training data: May 1, 2021</li>
                    <li>Release of test data: August 13, 2021</li>
                    <li>Testing results submission due:, August 15, 2021</li>
                    <li>Release of evaluation results: August 18, 2021</li>
                    <li>System description paper due: August 31, 2021</li>
                    <li>Notification of Acceptance: September 5, 2021</li>
                    <li>Camera-ready deadline: September 10, 2021</li>
                </ul>
            </div>
        </div>

        <div class="part">
            <h2>References</h2>
            <div class="list">
                <ul>
                    <li>Rafael A. Calvo, and Sunghwan Mac Kim. 2013. Emotions in text: dimensional and categorical models. Computational Intelligence, 29(3):527-543.</li>
                    <li>Munmun De Choudhury, Scott Counts, and Michael Gamon. 2012. Not all moods are created equal! Exploring human emotional states in social media. In Proc. of ICWSM-12, pages 66-73.</li>
                    <li>Steven Du and Xi Zhang. 2016. Aicyber’s system for IALP 2016 shared task: Character-enhanced word vectors and Boosted Neural Networks, in Proc. of IALP-16, pages 161–163.</li>
                    <li>Pranav Goel, Devang Kulshreshtha, Prayas Jain and Kaushal Kumar Shukla. 2017. Prayas at EmoInt 2017: An Ensemble of Deep Neural Architectures for Emotion Intensity Prediction in Tweets, in Proc. of WASSA-17, pages 58–65.</li>
                    <li>Sunghwan Mac Kim, Alessandro Valitutti, and Rafael A. Calvo. 2010. Evaluation of unsupervised emotion models to textual affect recognition. In Proc. of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text, pages 62-70.</li>
                    <li>N. Malandrakis, A. Potamianos, E. Iosif, and S. Narayanan. 2013. Distributional semantic models for affective text analysis. IEEE Transactions on Audio, Speech, and Language Processing, 21(11): 2379-2392.</li>
                    <li>Myriam Munezero, Tuomo Kakkonen, and Calkin S. Montero. 2011. Towards automatic detection of antisocial behavior from texts. In Proc. of the Workshop on Sentiment Analysis where AI meets Psychology (SAAIP) at IJCNLP-11, pages 20-27.</li>
                    <li>Georgios Paltoglou, Mathias Theunis, Arvid Kappas, and Mike Thelwall. 2013. Predicting emotional responses to long informal text. IEEE Trans. Affective Computing, 4(1):106-115.</li>
                    <li>Jie Ren and Jeffrey V. Nickerson. 2014. Online review systems: How emotional language drives sales. In Proc. of AMCIS-14.</li>
                    <li>James A. Russell. 1980. A circumplex model of affect. Journal of Personality and Social Psychology, 39(6):1161.</li>
                    <li>Wen-Li Wei, Chung-Hsien Wu, and Jen-Chun Lin. 2011. A regression approach to affective rating of Chinese words from ANEW. In Proc. of ACII-11, pages 121-131.</li>
                    <li>Liang-Chih Yu, Cheng-Wei Lee, Huan-Yi Pan, Chih-Yueh Chou, Po-Yao Chao, Zhi-Hong Chen, Shu-Fen Tseng, Chien-Lung Chan and K. Robert Lai. 2018. Improving early prediction of academic failure using sentiment analysis on self-evaluated comments, Journal of Computer Assisted Learning, 34(4):358-365.</li>
                    <li>Liang-Chih Yu, Lung-Hao Lee, Shuai Hao, Jin Wang, Yunchao He, Jun Hu, K. Robert Lai, and Xuejie Zhang. 2016a. Building Chinese affective resources in valence-arousal dimensions. In Proc. of NAACL/HLT-16, pages 540-545.</li>
                    <li>Liang-Chih Yu, Lung-Hao Lee, Jin Wang and Kam-Fai Wong. 2017. IJCNLP-2017 Task 2: Dimensional sentiment analysis for Chinese phrases, in Proc. of IJCNLP-17, pages 9-16.</li>
                    <li>Liang-Chih Yu, Lung-Hao Lee and Kam-Fai Wong. 2016b. Overview of the IALP 2016 shared task on dimensional sentiment analysis for Chinese words, in Proc. of IALP-16, pages 156-160.</li>
                    <li>Liang-Chih Yu, Jin Wang, K. Robert Lai and Xuejie Zhang. 2020. Pipelined neural networks for phrase-level sentiment intensity prediction, IEEE Transactions on Affective Computing, 11(3), 447-458.</li>
                    <li>Jin Wang, Liang-Chih Yu, K. Robert Lai and Xuejie Zhang. 2016. Community-based weighted graph model for valence-arousal prediction of affective words, IEEE/ACM Trans. Audio, Speech and Language Processing, 24(11):1957-1968.</li>
                    <li>Jin Wang, Liang-Chih Yu, K. Robert Lai and Xuejie Zhang. 2020. Tree-structured regional CNN- LSTM model for dimensional sentiment analysis, IEEE/ACM Transactions on Audio Speech and Language Processing, 28, 581–591.</li>
                    <li>Chuhan Wu, Fangzhao Wu, Yongfeng Huang, Sixing Wu and Zhigang Yuan. 2017. THU NGN at IJCNLP-2017 Task 2: Dimensional sentiment analysis for Chinese phrases with deep LSTM, in Proc. of IJCNLP-17, pages 42-52.</li>
                    <li>Suyang Zhu, Shoushan Li and Guodong Zhou. 2019. Adversarial attention modeling for multi- dimensional emotion regression, in Proc. of ACL-19, pages 471–480.</li>
                </ul>
            </div>
        </div>
    </div>

    
    <!-- ============================================================================ -->
    <div class="organization" id="org">
        <h1>Organization</h1>
        <div class="flex">

            <div class="flex_center">

                <div class="wrap">
                    <h2>Honorary Chair</h2>
                    <div class="item">
                        <img src="image/organization/Jing-Yang-Jou.jpg" alt="">
                        <div class="people">
                            <h3>Jing-Yang Jou</h3>
                            <p>National Central University</p>
                        </div>
                    </div> 
                </div>
                
                <div class="wrap">
                    <h2>Conference Chairs</h2>

                    <div class="item">
                        <img src="image/organization/Lung-Hao-Lee.jpg" alt="">
                        <div class="people">
                            <h3>Lung-Hao Lee</h3>
                            <p>National Central University</p>
                        </div>
                    </div>
                    
                    <div class="item">
                        <img src="image/organization/Chia-Hui-Chang.jpg" alt="">
                        <div class="people">
                            <h3>Chia-Hui Chang</h3>
                            <p>National Central University</p>
                        </div>
                    </div>
                    
                    <div class="item">
                        <img src="image/organization/Kuan-Yu-Chen.jpg" alt="">
                        <div class="people">
                            <h3>Kuan-Yu Chen</h3>
                            <p>National Taiwan University of Science and Technology</p>
                        </div>
                    </div>
                    
                </div>

                <div class="wrap">
                    <h2>Program Chairs</h2>
                    <div class="item">
                        <img src="image/organization/Yung-Chun-Chang.jpeg" alt="">
                        <div class="people">
                            <h3>Yung-Chun Chang</h3>
                            <p>Taipei Medical University</p>
                        </div>
                        
                    </div>
                    
                    <div class="item">
                        <img src="image/organization/Yi-Chin-Huang.jpg" alt="">
                        <div class="people">
                            <h3>Yi-Chin Huang</h3>
                            <p>National Pingtung University</p>
                        </div>
                        
                    </div>
                    
                </div>

                
                <div class="wrap">
                    <h2>Tutorial Chair</h2>
                    <div class="item">
                        <img src="image/organization/Hung-Yi-Lee.jpg" alt="">
                        <div class="people">
                            <h3>Hung-Yi Lee</h3>
                            <p>National Taiwan University</p>
                        </div>
                    </div>
                    
                </div>
            
                
                <div class="wrap">
                    <h2>Publication Chair</h2>
                    <div class="item">
                        <img src="image/organization/Jheng-Long-Wu.jpg" alt="">
                        <div class="people">
                            <h3>Jheng-Long Wu</h3>
                            <p>Soochow University</p>
                        </div>
                    </div>
                    
                </div>

                <div class="wrap">
                    <h2>Special Session Chair</h2>
                    <div class="item">
                        <img src="image/Special_Session/徐峻賢.jpg" alt="">
                        <div class="people">
                            <h3>Chun-Hsien Hsu</h3>
                            <p>National Central University</p>
                        </div>
                    </div>
                </div>

                <div class="wrap">
                    <h2>Shared Task Chair</h2>
                    <div class="item">
                        <img src="image/share_task/Liang-Chih-Yu.jpg" alt="">
                        <div class="people">
                            <h3>Liang-Chih Yu</h3>
                            <p>Yuan Ze University</p>
                        </div>
                    </div>
                </div>

            </div>
            
            <div class="flex_center">

                <div class="space"></div>

                <div class="wrap">
                    <h2>Organized by</h2>
                    <div class="org_block">
                        <img src="image/organization/org_unit/NCU_logo.png" alt="">
                        <p>National Central University</p>
                    </div>

                    <div class="org_block">
                        <img src="image/organization/org_unit/NTUST_logo.png" alt="">
                        <p>National Taiwan University of Science and Technology</p>
                    </div>

                    <div class="org_block">
                        <img src="image/organization/org_unit/ACLCLP_logo.png" alt="">
                        <p>The Association for Computational Linguistics and Chinese Language Processing</p>
                    </div>
                </div>

                <div class="wrap">
                    <h2>Co-Organized by</h2>
                    <div class="org_block">
                        <a href="http://ai.ntu.edu.tw/" target="_blank" title="uninstructed"><img id="ESUN" src="image/organization/org_unit/AINTU.png" alt=""></a>
                    </div>
                    <div class="org_block">
                        <a href="https://pairlabs.ai/" target="_blank" title="uninstructed"><img id="ESUN" src="image/organization/org_unit/PAIR.png" alt=""></a>
                    </div>
                    <div class="org_block">
                        <a href="http://aibmrc.csie.ncku.edu.tw/" target="_blank" title="uninstructed"><img id="ESUN" src="image/organization/org_unit/AIBMRC.png" alt=""></a>
                    </div>
                </div>

                <div class="wrap">
                    <h2>Supported by</h2>
                    <div class="org_block">
                        <img id="MST"src="image/organization/org_unit/MST_logo.png" alt="">
                    </div>
                    <div class="org_block">
                        <img id="MST" src="image/organization/org_unit/ROC_Ministry_of_Education_Seal.png" alt="">
                    </div>
                </div>

                <div class="wrap">
                    <h2>Sponsored by</h2>
                    <div class="org_block">
                        <a href="https://www.esunfhc.com/zh-tw/" target="_blank" title="uninstructed"><img id="ESUN" src="image/organization/org_unit/esunfhc.png" alt=""></a>
                    </div>
                    <div class="org_block">
                        <a href="https://www.cyberon.com.tw/" target="_blank" title="uninstructed"><img id="ESUN" src="image/organization/org_unit/cyberon.png" alt=""></a>
                    </div>
                    <div class="org_block">
                        <a href="https://www.chttl.com.tw/ch/index/index.html" target="_blank" title="uninstructed"><img id="ESUN" src="image/organization/org_unit/CTL.png" alt=""></a>
                    </div>
                </div>

            </div>

        </div>

        <div class='flex' id='PT'>
            <h2 id='program_title'>Program Committee</h2>
            <h4 id='program_title_note'>Name (sorted by last names), Organization</h4>
        </div>
        
        <div class="flex" id="flex-pc">
            
            <div class="flex_program">

                <div class="item">
                    <div class="people">
                        <h3>Jia-Wei Chang（張家瑋),</h3>
                        <p>National Taichung University of Science</p>
                    </div>
                </div>

                <div class="item">
                    <div class="people">
                        <h3>Ru-Yng Chang (張如瑩),</h3>
                        <p>ai clerk international co., Itd</p>
                    </div>
                </div>
                
                <div class="item">
                    <div class="people">
                        <h3>Chung-Chi Chen (陳重吉),</h3>
                        <p>National Taiwan University</p>
                    </div>
                </div>
                
                <div class="item">
                    <div class="people">
                        <h3>Yun-Nung Chen (陳縕儂),</h3>
                        <p>National Taiwan University</p>
                    </div>
                </div>
                
                <div class="item">
                    <div class="people">
                        <h3>Yu-Tai Chien (簡宇泰),</h3>
                        <p>National Taipei University of Business</p>
                    </div>
                </div>
                
                <div class="item">
                    <div class="people">
                        <h3>Hong-Jie Dai (戴鴻傑),</h3>
                        <p>National Kaohsiung University of Science and Technology</p>
                    </div>
                </div>
                
                <div class="item">
                    <div class="people">
                        <h3>Min-Yuh Day (戴敏育),</h3>
                        <p>National Taipei University</p>
                    </div>
                </div>
                
                <div class="item">
                    <div class="people">
                        <h3>Yu-Lun Hsieh (謝育倫),</h3>
                        <p>CloudMile</p>
                    </div>
                </div>
                
                <div class="item">
                    <div class="people">
                        <h3>Wen-Lian Hsu (許聞廉),</h3>
                        <p>Asia University</p>
                    </div>
                </div>
                
                <div class="item">
                    <div class="people">
                        <h3>Hen-Hsen Huang (黃瀚萱),</h3>
                        <p>Academia Sinica</p>
                    </div>
                </div>
                
                <div class="item">
                    <div class="people">
                        <h3>Jeih-weih Hung (洪志偉),</h3>
                        <p>National Chi Nan University</p>
                    </div>
                </div>

                <div class="item">
                    <div class="people">
                        <h3>Chih-Hao Ku (顧值豪),</h3>
                        <p>Cleveland State University</p>
                    </div>
                </div>

            </div>

            <div class="flex_program">
                
                <div class="item">
                    <div class="people">
                        <h3>Ying-Hui Lai (賴穎暉),</h3>
                        <p>National Yang Ming Chiao Tung University</p>
                    </div>
                </div>
                
                <div class="item">
                    <div class="people">
                        <h3>Cheng-Te Li (李政德),</h3>
                        <p>National Cheng Kung University</p>
                    </div>
                </div>
                
                <div class="item">
                    <div class="people">
                        <h3>Chun-Yen Lin (林君彥),</h3>
                        <p>Taipei Medical University</p>
                    </div>
                </div>
                
                <div class="item">
                    <div class="people">
                        <h3>Jen-Chun Lin (林仁俊),</h3>
                        <p>Academia Sinica</p>
                    </div>
                </div>

                <div class="item">
                    <div class="people">
                        <h3>Szu-Yin Lin (林斯寅),</h3>
                        <p>National llan University</p>
                    </div>
                </div>

                <div class="item">
                    <div class="people">
                        <h3>Shih-Hung Liu (劉士弘),</h3>
                        <p>Digiwin</p>
                    </div>
                </div>
                
                <div class="item">
                    <div class="people">
                        <h3>Chao-Lin Liu (劉昭麟),</h3>
                        <p>National Chengchi University</p>
                    </div>
                </div>
                
                <div class="item">
                    <div class="people">
                        <h3>Jenn-Long Liu (劉振隆),</h3>
                        <p>I-Shou University</p>
                    </div>
                </div>
                
                <div class="item">
                    <div class="people">
                        <h3>Yi-Fen Liu (劉怡芬),</h3>
                        <p>Feng Chia University</p>
                    </div>
                </div>
                
                <div class="item">
                    <div class="people">
                        <h3>Wen-Hsiang Lu (盧文祥),</h3>
                        <p>National Cheng Kung University</p>
                    </div>
                </div>

                <div class="item">
                    <div class="people">
                        <h3>Shang-Pin Ma (馬尚彬),</h3>
                        <p>National Taiwan Ocean University</p>
                    </div>
                </div>

                <div class="item">
                    <div class="people">
                        <h3>Emily Chia-Yu Su (蘇家玉),</h3>
                        <p>Taipei Medical University</p>
                    </div>
                </div>

            </div>

            <div class="flex_program">
                
                <div class="item">
                    <div class="people">
                        <h3>Ming-Hsiang Su (蘇明祥),</h3>
                        <p>Soochow University</p>
                    </div>
                </div>
                
                <div class="item">
                    <div class="people">
                        <h3>Richard Tzong-Han Tsai (蔡宗翰),</h3>
                        <p>Naitonal Central University</p>
                    </div>
                </div>

                <div class="item">
                    <div class="people">
                        <h3>Chun-Wei Tung (童俊維),</h3>
                        <p>National Health Research Institutes</p>
                    </div>
                </div>
                
                <div class="item">
                    <div class="people">
                        <h3>Hsin-Min Wang (王新民),</h3>
                        <p>Academia Sinica</p>
                    </div>
                </div>
                
                <div class="item">
                    <div class="people">
                        <h3>Jenq-Haur Wang (王正豪),</h3>
                        <p>National Taipei University of Technology</p>
                    </div>
                </div>
                
                <div class="item">
                    <div class="people">
                        <h3>Yu-Cheng Wang (王昱晟),</h3>
                        <p>Lunghwa University of Science and Technology</p>
                    </div>
                </div>
                
                <div class="item">
                    <div class="people">
                        <h3>Jheng-Long wu (吳政隆),</h3>
                        <p>Soochow University</p>
                    </div>
                </div>
                
                <div class="item">
                    <div class="people">
                        <h3>Shih-Hung wu (吳世弘),</h3>
                        <p>Chaoyang University of Technology</p>
                    </div>
                </div>
                
                <div class="item">
                    <div class="people">
                        <h3>Jui-Feng Yeh (葉瑞峰),</h3>
                        <p>National Chiayi University</p>
                    </div>
                </div>

                <div class="item">
                    <div class="people">
                        <h3>Liang-Chih Yu (禹良治),</h3>
                        <p>Yuan Ze University</p>
                    </div>
                </div>
                
            </div>

        </div>
    </div>

    <!-- ============================================================================ -->
    <div class="footer">
        &copy;ROCLING 2021, National Central University (NCU), Taoyuan City, Taiwan || Email: rocling2021@gmail.com || Updated: October 4, 2021
    </div>

    <!-- 匯入main javascript -->
    <script src="main.js"></script>

</body>

</html>